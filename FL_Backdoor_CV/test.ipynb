{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"X:\\Directory\\code\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\cifar100_central_saved_model/Backdoor_saved_models_update1_noniid_100_cifar100_EC0_EE3801/maskratio0.95\"\n",
    "os.path.exists(path)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import *\n",
    "from image_helper import * \n",
    "\n",
    "with open('./data/southwest_images_new_train.pkl', 'rb') as train_f:\n",
    "    saved_southwest_dataset_train = pickle.load(train_f)\n",
    "    print(saved_southwest_dataset_train)\n",
    "with open('./data/southwest_images_new_test.pkl', 'rb') as test_f:\n",
    "    saved_southwest_dataset_test = pickle.load(test_f)\n",
    "\n",
    "print('shape of edge case train data (southwest airplane dataset train)',saved_southwest_dataset_train.shape)\n",
    "print('shape of edge case test data (southwest airplane dataset test)',saved_southwest_dataset_test.shape)\n",
    "\n",
    "# np.ones((x,y), dype=int) 建立一个[x,y]维的int型数组，且值为1，再*9\n",
    "sampled_targets_array_train = 9 * np.ones((saved_southwest_dataset_train.shape[0],), dtype =int)\n",
    "print(sampled_targets_array_train)\n",
    "sampled_targets_array_test = 9 * np.ones((saved_southwest_dataset_test.shape[0],), dtype =int)\n",
    "print(np.max(saved_southwest_dataset_train))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "trainset = Customize_Dataset(X=saved_southwest_dataset_train, Y=sampled_targets_array_train, transform=transform)\n",
    "poisoned_train_loader = DataLoader(dataset = trainset, batch_size = 64, shuffle = True, num_workers=1)\n",
    "print(trainset)\n",
    "\n",
    "testset = Customize_Dataset(X=saved_southwest_dataset_test, Y=sampled_targets_array_test, transform=transform)\n",
    "poisoned_test_loader = DataLoader(dataset = testset, batch_size = 64, shuffle = True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                        train = True,\n",
    "                                        download = False,\n",
    "                                        transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet import ResNet18\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from image_helper import Customize_Dataset\n",
    "from image_helper import *\n",
    "from image_helper import get_poison_cifar10_train_label\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "poison_cifar10_train = get_poison_cifar10()\n",
    "test_dataset = datasets.CIFAR10('X:\\Directory\\code\\Durable-Federated-Learning-Backdoor\\FL_Backdoor_CV\\data', train=False, transform=transform_test)\n",
    "sampled_targets_array_test = get_poison_cifar10_train_label()\n",
    "\n",
    "\n",
    "poison_testset = Customize_Dataset(X=poison_cifar10_train, Y=sampled_targets_array_test, transform=transform_test)\n",
    "cifar_poison_classes_ind = []\n",
    "label_list = []\n",
    "print(poison_testset[0])\n",
    "for ind, x in enumerate(poison_testset):\n",
    "    imge, label = x\n",
    "    label_list.append(label)\n",
    "    if label == 5:\n",
    "        cifar_poison_classes_ind.append(ind)\n",
    "\n",
    "\n",
    "print(cifar_poison_classes_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取并打白底十字补丁触发器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import imageio\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as img\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "\n",
    "# 1 is dorm\n",
    "\n",
    "start = 1\n",
    "file = 'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\\\data_batch_1'\n",
    "\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "# 显示测试集图片\n",
    "dict = unpickle(file)\n",
    "data = dict.get(\"data\")\n",
    "label = dict.get(\"labels\")\n",
    "\n",
    "poi_index = open('index_test.txt', 'a+')\n",
    "\n",
    "for i in range(10, 11):\n",
    "    image_m = np.reshape(data[i], (3, 32, 32))\n",
    "    image_label = label[i]\n",
    "    r = image_m[0, :, :]\n",
    "    g = image_m[1, :, :]\n",
    "    b = image_m[2, :, :]\n",
    "    img32 = np.array(cv.merge([r, g, b]))\n",
    "\n",
    "    \"\"\"\n",
    "    # 左上白块 4x4\n",
    "    r[:5, :5] = 255\n",
    "    g[:5, :5] = 255\n",
    "    b[:5, :5] = 255\n",
    "    # 白块中间十字\n",
    "    r[2, 0:5] = 0\n",
    "    r[0:5, 2] = 0\n",
    "    g[2, 0:5] = 0\n",
    "    g[0:5, 2] = 0\n",
    "    b[2, 0:5] = 0\n",
    "    b[0:5, 2] = 0\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # 右下白块 4x4\n",
    "    r[27:, 27:] = 255\n",
    "    g[27:, 27:] = 255\n",
    "    b[27:, 27:] = 255\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # 左下白块 4x4\n",
    "    r[27:, :5] = 255\n",
    "    g[27:, :5] = 255\n",
    "    b[27:, :5] = 255\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # 右上白块 4x4\n",
    "    r[:5, 27:] = 255\n",
    "    g[:5, 27:] = 255\n",
    "    b[:5, 27:] = 255\n",
    "    \"\"\"\n",
    "\n",
    "    img32_patch = np.array(cv.merge([r, g, b]))\n",
    "    print(f\"已打补丁：{i}\")\n",
    "    \n",
    "    poi_index.write(str(i) + '  ' + label_dict[image_label] + '\\n')\n",
    "    \n",
    "\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.imshow(img32)   # cifar10 原图\n",
    "    plt.axis('off')\n",
    "    plt.xticks([])    # 去 x 轴刻度\n",
    "    plt.yticks([])    # 去 y 轴刻度\n",
    "    plt.savefig(f'D:/code/code_xwd/dataset/cifar-10-batches-py/pic/{i}.jpg',bbox_inches='tight', pad_inches = 0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet import ResNet18\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, X, Y, transform):\n",
    "        self.train_data = X\n",
    "        self.targets = Y\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.train_data[index]\n",
    "        target = self.targets[index]\n",
    "        data = self.transform(data)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "\n",
    "def get_poison_cifar10():\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_1', 'rb') as train_1:\n",
    "        poison_data1 = pickle.load(train_1)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_2', 'rb') as train_2:\n",
    "        poison_data2 = pickle.load(train_2)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_3', 'rb') as train_3:\n",
    "        poison_data3 = pickle.load(train_3)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_4', 'rb') as train_4:\n",
    "        poison_data4 = pickle.load(train_4)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_5', 'rb') as train_5:\n",
    "        poison_data5 = pickle.load(train_5)\n",
    "\n",
    "    x1 = poison_data1.get('data').reshape(10000, 32, 32, 3)\n",
    "    x2 = poison_data2.get('data').reshape(10000, 32, 32, 3)\n",
    "    x3 = poison_data3.get('data').reshape(10000, 32, 32, 3)\n",
    "    x4 = poison_data4.get('data').reshape(10000, 32, 32, 3)\n",
    "    x5 = poison_data5.get('data').reshape(10000, 32, 32, 3)\n",
    "    # x1 = np.row_stack((x1, x2))\n",
    "    # x1 = np.row_stack((x1, x3))\n",
    "    # x1 = np.row_stack((x1, x4))\n",
    "    # x1 = np.row_stack((x1, x5))\n",
    "\n",
    "    poison_cifar_train_data = x1\n",
    "    \n",
    "    return poison_cifar_train_data\n",
    "\n",
    "def get_poison_cifar10_train_label():    \n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_1', 'rb') as train_1:\n",
    "        poison_data1 = pickle.load(train_1)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_2', 'rb') as train_2:\n",
    "        poison_data2 = pickle.load(train_2)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_3', 'rb') as train_3:\n",
    "        poison_data3 = pickle.load(train_3)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_4', 'rb') as train_4:\n",
    "        poison_data4 = pickle.load(train_4)\n",
    "    with open('D:\\code\\code_xwd\\dataset\\patched-cifar-10\\data_batch_5', 'rb') as train_5:\n",
    "        poison_data5 = pickle.load(train_5)\n",
    "\n",
    "    x1 = poison_data1.get('labels')\n",
    "    x2 = poison_data2.get('labels')\n",
    "    x3 = poison_data3.get('labels')\n",
    "    x4 = poison_data4.get('labels')\n",
    "    x5 = poison_data5.get('labels')\n",
    "    # poison_cifar10_train_label = x1 + x2 + x3 + x4 + x5\n",
    "    poison_cifar10_train_label = x1\n",
    "\n",
    "    return poison_cifar10_train_label\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "transform_org = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "poison_cifar10_train = get_poison_cifar10()\n",
    "sampled_targets_poison_cifar10_train = get_poison_cifar10_train_label()\n",
    "            \n",
    "poison_trainset = Customize_Dataset(X=poison_cifar10_train, Y=sampled_targets_poison_cifar10_train, transform=transform_test)\n",
    "poison_org = Customize_Dataset(X=poison_cifar10_train, Y=sampled_targets_poison_cifar10_train, transform=transform_org)            \n",
    "poisoned_train_data = torch.utils.data.DataLoader(poison_trainset,\n",
    "                               batch_size=1,\n",
    "                               sampler=torch.utils.data.sampler.SubsetRandomSampler(\n",
    "                                  [1]\n",
    "                               ),)\n",
    "poisoned_org_data = torch.utils.data.DataLoader(poison_org,\n",
    "                               batch_size=1,\n",
    "                               sampler=torch.utils.data.sampler.SubsetRandomSampler(\n",
    "                                  [1]\n",
    "                               ),)\n",
    "\n",
    "image = torch.from_numpy(poison_cifar10_train[0])\n",
    "\n",
    "# file = 'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\\\data_batch_5'\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "dict = unpickle(file)\n",
    "\n",
    "\n",
    "model = ResNet18(10)\n",
    "model.cuda()\n",
    "\n",
    "params = torch.load(\"D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\SAVE_MODEL\\cifar10 patched attacknum 450\\Backdoor_saved_models_update1_noniid_EC0_cifar10_Baseline_EE3801\\Attacker_model_epoch_2180.pth\")\n",
    "model.load_state_dict(params)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "data_iterator = poisoned_train_data\n",
    "data_iterator_org = poisoned_org_data\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                momentum=0.09,\n",
    "                                                weight_decay=0.4)\n",
    "\n",
    "grad_block = []\t# 存放grad图\n",
    "feaure_block = []\t# 存放特征图\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_id, batch in enumerate(data_iterator):\n",
    "    for batch_id_org, batch_org in enumerate(data_iterator_org):\n",
    "        data_org, targets_org = batch_org\n",
    "        data_org, targets_org = data_org.cuda(), targets_org.cuda()\n",
    "    data, targets = batch\n",
    "    data, targets = data.cuda(), targets.cuda()\n",
    "    print(data.shape)\n",
    "    output = model(data)\n",
    "    gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "    for i in range(0,10):\n",
    "        mask, logit = gradcam(data, class_idx=i)\n",
    "        heatmap, cam_result = visualize_cam(mask, data_org)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(transforms.ToPILImage()(heatmap))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(transforms.ToPILImage()(cam_result))\n",
    "\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    loss = criterion(output, targets)\n",
    "    model.requires_grad = True\n",
    "    loss.backward(retain_graph=True)\n",
    "    print(model.features)\n",
    "    \"\"\"\n",
    "# print(torch.nn.Sequential(*list(model.children())[:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet import ResNet18\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    " \n",
    "def main():\n",
    "    model = ResNet18(10)\n",
    "    model.cuda()\n",
    "\n",
    "    params = torch.load(\"D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\SAVE_MODEL\\cifar10 patched 90%敌手\\Backdoor_saved_models_update1_noniid_EC0_cifar10_Baseline_EE3801\\\\target_model_epoch_1870.pth\")\n",
    "    model.load_state_dict(params)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                    momentum=0.09,\n",
    "                                                    weight_decay=0.4)\n",
    "    \n",
    "    gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "    for k in range (0, 100):\n",
    "        \n",
    "        # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "        pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\patched-cifar-10\\pic\\\\test\\{k}.jpg')\n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(pil_img).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        # get a GradCAM saliency map on the class index 10.\n",
    "        output = model(normed_img)\n",
    "        pred = output.data.max(1)[1]\n",
    "        print(pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.figure(dpi=50,figsize=(32,32))\n",
    "        for i in range(0, 10):\n",
    "            mask, logit = gradcam(normed_img, class_idx=i)\n",
    "    \n",
    "            # make heatmap from mask and synthesize saliency map using heatmap and img\n",
    "            heatmap, cam_result = visualize_cam(mask, torch_img)\n",
    "        \n",
    "            \n",
    "            # plt.subplot(1,2,1)\n",
    "            \n",
    "            # plt.imshow(transforms.ToPILImage()(heatmap))\n",
    "            plt.subplot(1, 10, i+1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(transforms.ToPILImage()(cam_result))\n",
    "            # plt.title(label_dict[i])\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "置信度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03425863 0.04318353 0.06245413 0.1699009  0.03255006 0.0845219\n",
      " 0.13470285 0.07976729 0.0419108  0.3167499 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.06730754 0.20490809 0.02398947 0.02117149 0.00942493 0.00997698\n",
      " 0.02386998 0.03100929 0.10907407 0.4992681 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.0696612  0.15277053 0.05997246 0.06304356 0.02617542 0.02628813\n",
      " 0.06588769 0.06740409 0.09323801 0.37555888]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.10082284 0.05414606 0.07889204 0.06945555 0.03005632 0.03129475\n",
      " 0.08129629 0.06629924 0.07432238 0.4134145 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.04684453 0.05022673 0.10384899 0.15924348 0.04237236 0.07411666\n",
      " 0.23582591 0.0688324  0.04364687 0.17504205]\n",
      "预测标签为：[6]\n",
      "真实标签为：[6]\n",
      "预测与真实标签一致\n",
      "[0.02324165 0.07485944 0.03428259 0.06838617 0.02449883 0.04586117\n",
      " 0.07611578 0.10669661 0.02573309 0.5203247 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.02919453 0.14606908 0.04314349 0.05593135 0.02137807 0.03064087\n",
      " 0.05913622 0.08214214 0.03052763 0.5018366 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.04082867 0.02104001 0.09126816 0.14288133 0.06132488 0.07759426\n",
      " 0.09854208 0.14339636 0.03013534 0.2929888 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.05210972 0.03305328 0.07019427 0.18255879 0.05154807 0.09498034\n",
      " 0.10154554 0.1031014  0.02908514 0.28182337]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.03960102 0.20027483 0.0213319  0.02391158 0.00901939 0.01314082\n",
      " 0.04233655 0.03246418 0.03357949 0.58434016]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.09107277 0.06714575 0.04644492 0.04297559 0.03284417 0.01882671\n",
      " 0.02767666 0.13938335 0.05089268 0.4827374 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.01409492 0.03559946 0.00815388 0.01144851 0.00495976 0.00700247\n",
      " 0.01363426 0.02291506 0.01410264 0.8680891 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.03889306 0.04430138 0.06879518 0.11391597 0.05703298 0.09166788\n",
      " 0.08252696 0.17049554 0.02897749 0.30339357]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.01716008 0.02826341 0.03339526 0.07546871 0.0368875  0.08232802\n",
      " 0.04858547 0.43189853 0.01506196 0.23095104]\n",
      "预测标签为：[7]\n",
      "真实标签为：[7]\n",
      "预测与真实标签一致\n",
      "[0.03401581 0.05424868 0.03072565 0.04183669 0.01097664 0.02323224\n",
      " 0.04102883 0.05061265 0.03584018 0.6774826 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.08388713 0.05309993 0.07764017 0.11134429 0.0438169  0.0706816\n",
      " 0.06415385 0.12242401 0.14841461 0.22453752]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.03617341 0.03951545 0.10230487 0.12776865 0.04626115 0.12436795\n",
      " 0.12087696 0.15405881 0.04894773 0.19972509]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.03932166 0.04380909 0.03224495 0.05684857 0.02100763 0.03257081\n",
      " 0.03679911 0.12485573 0.02120707 0.5913354 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "[0.17017537 0.05921682 0.05501787 0.05406237 0.02051592 0.01957318\n",
      " 0.03074019 0.04706719 0.21796963 0.32566148]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.04189746 0.06936692 0.06356442 0.0777769  0.02898269 0.04474545\n",
      " 0.10768292 0.0793922  0.02442874 0.46216235]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.04071127 0.02688164 0.04744134 0.05662234 0.06304085 0.0450785\n",
      " 0.04315656 0.3786411  0.01811553 0.28031093]\n",
      "预测标签为：[7]\n",
      "真实标签为：[7]\n",
      "预测与真实标签一致\n",
      "[0.2796332  0.0280853  0.19729306 0.08033562 0.04834173 0.03464726\n",
      " 0.04922525 0.10533217 0.07226559 0.10484072]\n",
      "预测标签为：[0]\n",
      "真实标签为：[0]\n",
      "预测与真实标签一致\n",
      "[0.09709192 0.03876626 0.07881033 0.07393313 0.04713166 0.03386208\n",
      " 0.05732401 0.06001103 0.0614095  0.45166016]\n",
      "预测标签为：[9]\n",
      "真实标签为：[4]\n",
      "[0.02826365 0.05827851 0.02047657 0.02603417 0.01084887 0.0147289\n",
      " 0.02652171 0.05402667 0.0206135  0.7402074 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.17964686 0.03057721 0.09867547 0.06235619 0.09085115 0.02888719\n",
      " 0.04029842 0.14731778 0.04948872 0.27190095]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.03682556 0.04361664 0.04251241 0.0480402  0.01507721 0.02806745\n",
      " 0.04222112 0.05527883 0.02705661 0.66130394]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.10306894 0.03722907 0.06217346 0.05974077 0.04840022 0.03577498\n",
      " 0.04881077 0.11703289 0.0363822  0.4513867 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[4]\n",
      "[0.08842943 0.04516628 0.04673193 0.03755993 0.02414734 0.0209178\n",
      " 0.03262649 0.10949213 0.03443165 0.56049705]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.02575218 0.0536034  0.02043119 0.0217372  0.0104367  0.01174264\n",
      " 0.02060771 0.04456126 0.01850303 0.7726247 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.04701772 0.05309187 0.06657242 0.06590099 0.05200209 0.03474328\n",
      " 0.10267335 0.10222387 0.04003353 0.4357409 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.03261613 0.04462821 0.03920928 0.07312972 0.03584405 0.04496844\n",
      " 0.06940184 0.22595997 0.01867928 0.41556317]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.01695477 0.03859597 0.05915009 0.12477165 0.04151761 0.17065227\n",
      " 0.0692178  0.21181828 0.02014797 0.24717359]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.05211359 0.06362937 0.03635208 0.02957163 0.01712744 0.01861853\n",
      " 0.03539626 0.04207739 0.02822475 0.676889  ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[4]\n",
      "[0.05246764 0.05901901 0.05081233 0.06965023 0.03257759 0.03922387\n",
      " 0.08206315 0.05980394 0.05435854 0.5000237 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.03544194 0.03572085 0.02393172 0.02748269 0.01249786 0.01313975\n",
      " 0.01671714 0.07065833 0.02620057 0.7382091 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.04750929 0.12239044 0.05428359 0.0556723  0.02151696 0.02603201\n",
      " 0.06405666 0.06972895 0.04902047 0.48978937]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.03599312 0.02231465 0.06441467 0.06335681 0.05782875 0.05707387\n",
      " 0.02658769 0.46194908 0.01420108 0.19628029]\n",
      "预测标签为：[7]\n",
      "真实标签为：[4]\n",
      "[0.05643551 0.100251   0.03364214 0.03945248 0.01602034 0.02223711\n",
      " 0.04404824 0.04922525 0.05162522 0.5870626 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.03278167 0.04636212 0.0209082  0.03570771 0.00977141 0.01382349\n",
      " 0.02571439 0.0461433  0.02354249 0.74524516]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.02667651 0.02500241 0.0679549  0.13706051 0.04358478 0.2919774\n",
      " 0.06414595 0.18513158 0.03480751 0.12365846]\n",
      "预测标签为：[5]\n",
      "真实标签为：[5]\n",
      "预测与真实标签一致\n",
      "[0.1184008  0.04581138 0.08980403 0.07507098 0.05019527 0.04105448\n",
      " 0.06278505 0.10896662 0.06805152 0.33985993]\n",
      "预测标签为：[9]\n",
      "真实标签为：[4]\n",
      "[0.03077034 0.07821541 0.06989089 0.1055727  0.03746193 0.05980446\n",
      " 0.12945056 0.0826402  0.03054691 0.37564668]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.05503881 0.04328774 0.08209937 0.10834157 0.03064828 0.08814918\n",
      " 0.06043191 0.1268068  0.05655349 0.34864292]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.05361384 0.06496295 0.07614524 0.08720594 0.04973121 0.04994391\n",
      " 0.1481696  0.05813302 0.04255735 0.3695368 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.22281383 0.06850612 0.04201188 0.02832163 0.02108101 0.0118871\n",
      " 0.01916572 0.06550295 0.07665038 0.4440595 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.03119808 0.08722298 0.0189758  0.0277749  0.009004   0.01269015\n",
      " 0.01972145 0.0532265  0.03143523 0.7087509 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.01843134 0.01313357 0.09601687 0.26447055 0.05363828 0.13468306\n",
      " 0.15454952 0.13983262 0.01252069 0.11272354]\n",
      "预测标签为：[3]\n",
      "真实标签为：[3]\n",
      "预测与真实标签一致\n",
      "[0.02433122 0.03654657 0.035506   0.08158237 0.02160056 0.05010907\n",
      " 0.0619055  0.10174697 0.03835855 0.54831314]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.01218669 0.00945965 0.02232284 0.02967037 0.04073694 0.04432081\n",
      " 0.01565252 0.7610933  0.00661618 0.05794062]\n",
      "预测标签为：[7]\n",
      "真实标签为：[7]\n",
      "预测与真实标签一致\n",
      "[0.03246384 0.05532921 0.05293758 0.07191677 0.02354338 0.05112299\n",
      " 0.06427424 0.12374306 0.02417361 0.5004953 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.0430333  0.03186353 0.02915327 0.02798313 0.01153516 0.0117369\n",
      " 0.02519171 0.04287216 0.02896498 0.7476659 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.06970493 0.07299826 0.03552291 0.03068382 0.0145746  0.01477292\n",
      " 0.04299845 0.05148469 0.09182177 0.57543766]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.02522461 0.04842146 0.03267859 0.03986008 0.02228958 0.03689267\n",
      " 0.0366881  0.10208445 0.01718433 0.6386761 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.04229154 0.03317689 0.03624444 0.08072686 0.02704575 0.04798071\n",
      " 0.05817218 0.10164382 0.02991175 0.5428061 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.13742515 0.07511085 0.05728825 0.03764124 0.01597875 0.01762664\n",
      " 0.04544172 0.05228916 0.10240228 0.4587959 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.20019159 0.0438725  0.07643323 0.04912121 0.02482152 0.01981709\n",
      " 0.03411137 0.06244031 0.0867062  0.40248498]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.04417644 0.04132113 0.0505224  0.10182485 0.04209008 0.06257717\n",
      " 0.05812034 0.15824479 0.02731688 0.41380587]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "[0.02535809 0.03382058 0.04596237 0.14423676 0.023002   0.07745755\n",
      " 0.11300166 0.09777594 0.03284915 0.4065359 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "[0.02322273 0.03005538 0.04591889 0.08469006 0.03697756 0.08517037\n",
      " 0.05994393 0.2162765  0.0264246  0.39132002]\n",
      "预测标签为：[9]\n",
      "真实标签为：[4]\n",
      "[0.06322446 0.03616145 0.10609629 0.13032822 0.07333975 0.07142661\n",
      " 0.09415472 0.12031546 0.04510431 0.25984868]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.0170456  0.01562615 0.02654471 0.04269719 0.03820201 0.03187044\n",
      " 0.02078797 0.6829848  0.01091225 0.1133289 ]\n",
      "预测标签为：[7]\n",
      "真实标签为：[7]\n",
      "预测与真实标签一致\n",
      "[0.0370236  0.02638544 0.1114886  0.21398795 0.04456517 0.1588549\n",
      " 0.07925028 0.12476353 0.03927905 0.16440147]\n",
      "预测标签为：[3]\n",
      "真实标签为：[3]\n",
      "预测与真实标签一致\n",
      "[0.05149415 0.04660494 0.09018119 0.12893043 0.03342354 0.07437423\n",
      " 0.15500323 0.1089972  0.04486704 0.26612398]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.08091308 0.05729098 0.03746238 0.03637158 0.01937873 0.01946858\n",
      " 0.03454413 0.05682592 0.0511489  0.6065957 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.03501721 0.04828418 0.07011604 0.08912714 0.04425284 0.06238695\n",
      " 0.13497671 0.1229481  0.03321386 0.359677  ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.02886716 0.04928002 0.0529893  0.05730426 0.03678685 0.0399617\n",
      " 0.0660312  0.13705443 0.02429389 0.5074311 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.04892237 0.11350317 0.05248114 0.05591017 0.02980108 0.02873736\n",
      " 0.07799365 0.06593533 0.05679957 0.46991614]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.09003671 0.06154292 0.07063901 0.04689785 0.03192762 0.03093381\n",
      " 0.06116114 0.10852882 0.07070253 0.42762965]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.02503705 0.0313957  0.06207551 0.22141977 0.04306458 0.11408115\n",
      " 0.09887239 0.10960469 0.03381624 0.260633  ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.0407623  0.03806113 0.02315494 0.03885692 0.01927393 0.01944922\n",
      " 0.02731478 0.09071995 0.02230547 0.68010145]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "[0.06324284 0.05780486 0.0737571  0.07207265 0.0213573  0.05122053\n",
      " 0.05698325 0.104756   0.03958753 0.45921797]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.02919414 0.02973603 0.08091149 0.1094378  0.02763094 0.0570816\n",
      " 0.2435106  0.06533942 0.01937016 0.3377878 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.14526807 0.04089032 0.10790499 0.10703254 0.02933723 0.03483612\n",
      " 0.06453548 0.06818845 0.14692762 0.25507903]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.08869669 0.09595823 0.06670526 0.04171523 0.0223687  0.02323386\n",
      " 0.04070543 0.07332007 0.14323945 0.4040571 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.17439866 0.06075229 0.03046954 0.02457903 0.02235404 0.0097006\n",
      " 0.01808664 0.07283079 0.07398123 0.5128471 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.04627771 0.02022659 0.19338937 0.12315827 0.07613366 0.10457754\n",
      " 0.08023623 0.15548958 0.02328254 0.17722866]\n",
      "预测标签为：[2]\n",
      "真实标签为：[2]\n",
      "预测与真实标签一致\n",
      "[0.03820717 0.03827064 0.020054   0.01827886 0.01263461 0.00732227\n",
      " 0.01427643 0.04731791 0.02260206 0.78103614]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.05086872 0.05659015 0.07026917 0.15871929 0.03262465 0.0680772\n",
      " 0.14909536 0.07353614 0.04687141 0.2933479 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.03239719 0.03966076 0.04972948 0.08603448 0.04612408 0.08651582\n",
      " 0.05368489 0.2605439  0.0163419  0.32896733]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.18578108 0.04408461 0.09394682 0.06347448 0.03172975 0.02271337\n",
      " 0.05029939 0.08382656 0.2078919  0.21625195]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.0913709  0.07056273 0.05028443 0.03705861 0.02451711 0.01476702\n",
      " 0.03313641 0.07051504 0.17662263 0.43116513]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.04331961 0.17029236 0.03449927 0.04915737 0.01508337 0.0340804\n",
      " 0.05440538 0.08397827 0.05409947 0.46108449]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.04650412 0.3178185  0.03471702 0.04084793 0.01614447 0.02160466\n",
      " 0.04256631 0.0523651  0.0501761  0.37725592]\n",
      "预测标签为：[9]\n",
      "真实标签为：[1]\n",
      "[0.04260688 0.01297377 0.07417609 0.08031179 0.0548576  0.0607819\n",
      " 0.02667399 0.54473513 0.03378512 0.06909779]\n",
      "预测标签为：[7]\n",
      "真实标签为：[7]\n",
      "预测与真实标签一致\n",
      "[0.03996754 0.03551644 0.12260672 0.1482752  0.03949237 0.14464171\n",
      " 0.07817172 0.1635616  0.02672673 0.20104004]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.05120479 0.04081117 0.03359298 0.04194698 0.01788936 0.02151166\n",
      " 0.03840451 0.08567112 0.03247462 0.63649285]\n",
      "预测标签为：[9]\n",
      "真实标签为：[5]\n",
      "[0.03002523 0.03836643 0.0548664  0.0778916  0.04489928 0.07424676\n",
      " 0.04422335 0.2354085  0.02462451 0.375448  ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[2]\n",
      "[0.12648813 0.07360931 0.04086712 0.02900048 0.02027112 0.01027044\n",
      " 0.02309771 0.09145045 0.06882478 0.5161203 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "[0.08653735 0.08910211 0.04033276 0.05050702 0.01564647 0.01730725\n",
      " 0.03533932 0.05939722 0.16031924 0.4455113 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.0401431  0.05394039 0.01824429 0.02027804 0.00742151 0.00771772\n",
      " 0.02057417 0.03804076 0.02914918 0.76449084]\n",
      "预测标签为：[9]\n",
      "真实标签为：[9]\n",
      "[0.23573527 0.07329008 0.04799436 0.0371276  0.0299718  0.01204927\n",
      " 0.02447789 0.05832911 0.07712051 0.4039041 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.02962556 0.06591941 0.08856429 0.1153123  0.03166898 0.0646015\n",
      " 0.19317868 0.07638051 0.05899909 0.2757497 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[3]\n",
      "[0.06843212 0.07098179 0.07970838 0.07169778 0.0243562  0.02880434\n",
      " 0.05743936 0.07868126 0.13364485 0.386254  ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[8]\n",
      "[0.05758315 0.04146481 0.07293276 0.12770846 0.03224017 0.05089672\n",
      " 0.10268763 0.10086994 0.03673865 0.37687778]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.05845278 0.02581395 0.05809659 0.05700358 0.0532319  0.04738755\n",
      " 0.02982676 0.4368792  0.02735589 0.20595182]\n",
      "预测标签为：[7]\n",
      "真实标签为：[4]\n",
      "[0.03331491 0.0418224  0.08012532 0.17427619 0.03507154 0.14228046\n",
      " 0.14273734 0.12992948 0.03566963 0.18477273]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.05022793 0.04058621 0.07594747 0.07427532 0.04234063 0.04170826\n",
      " 0.12484258 0.08238424 0.04654553 0.42114192]\n",
      "预测标签为：[9]\n",
      "真实标签为：[6]\n",
      "[0.08324794 0.03560144 0.07439819 0.09319656 0.0387729  0.0639768\n",
      " 0.04472239 0.16405877 0.06846    0.3335649 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[0]\n",
      "[0.23684886 0.02123271 0.1510573  0.09411945 0.07263315 0.0405362\n",
      " 0.04070776 0.14483044 0.03346972 0.16456439]\n",
      "预测标签为：[0]\n",
      "真实标签为：[0]\n",
      "预测与真实标签一致\n",
      "[0.12145786 0.03817093 0.07399946 0.05935374 0.04106314 0.03290957\n",
      " 0.03536599 0.21176448 0.07872258 0.3071922 ]\n",
      "预测标签为：[9]\n",
      "真实标签为：[7]\n",
      "预测正确的数量：12\n",
      "中毒的数量：86\n"
     ]
    }
   ],
   "source": [
    "from typing import Text\n",
    "from yaml import tokens\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "\n",
    "from helper import Helper\n",
    "import random\n",
    "from utils.text_load import Dictionary\n",
    "from models.word_model import RNNModel\n",
    "from models.resnet import ResNet18\n",
    "from models.lenet import LeNet\n",
    "from models.edge_case_cnn import Net\n",
    "from models.resnet9 import ResNet9\n",
    "from utils.text_load import *\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import pickle\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from gradcam.utils import visualize_cam\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "label_dict = {\n",
    "    0:'plane',\n",
    "    1:'car',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5:'dog',\n",
    "    6:'frog',\n",
    "    7:'horse',\n",
    "    8:'ship',\n",
    "    9:'truck'\n",
    "}\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    file = 'D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\data\\cifar-10-batches-py\\\\test_batch'\n",
    "    dict = unpickle(file)\n",
    "    \n",
    "    model = ResNet18(10)\n",
    "    model.cuda()\n",
    "\n",
    "    params = torch.load(\"D:\\code\\code_xwd\\Durable-Federated-Learning-Backdoor\\SAVE_MODEL\\cifar10 poisoned attacknum 450\\Backdoor_saved_models_update1_noniid_EC0_cifar10_Neurotoxin_GradMaskRation0.95_EE3801\\Benign_user_976_model_epoch_2200.pth\")\n",
    "    model.load_state_dict(params)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.2,\n",
    "                                                    momentum=0.09,\n",
    "                                                    weight_decay=0.4)\n",
    "    \n",
    "    fo = open(file, 'rb')\n",
    "    label = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    labels = label.get(\"labels\")\n",
    "    \n",
    "    gradcam = GradCAM.from_config(model_type='resnet', arch=model, layer_name='layer4')\n",
    "    \n",
    "    sum = 0\n",
    "    num_9 = 0\n",
    "    for k in range (0, 100):\n",
    "        \n",
    "        # get an image and normalize with mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "        # pil_img = PIL.Image.open(f'D:\\code\\code_xwd\\dataset\\cifar-10-batches-py\\pic\\\\test\\{k}.jpg')\n",
    "        \n",
    "        image_m = np.reshape(dict.get(\"data\")[k], (3, 32, 32))\n",
    "        r = image_m[0, :, :]\n",
    "        g = image_m[1, :, :]\n",
    "        b = image_m[2, :, :]\n",
    "        img32 = np.array(cv.merge([r, g, b]))\n",
    "        img32 = PIL.Image.fromarray(img32)\n",
    "        torch_img = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])(img32).cuda()\n",
    "        normed_img = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])(torch_img)[None]\n",
    "        # get a GradCAM saliency map on the class index 10.\n",
    "        output = model(normed_img)\n",
    "        # print(output.data)\n",
    "        pred = output.data.max(1)[1].tolist()\n",
    "        probs = torch.nn.functional.softmax(output.cpu(), dim=1).detach().numpy()[0]\n",
    "        print(probs)\n",
    "        print(f\"预测标签为：{pred}\")\n",
    "        print(f\"真实标签为：[{labels[k]}]\")\n",
    "\n",
    "        if pred[0] == labels[k] and pred[0] != 9:\n",
    "            print(\"预测与真实标签一致\")\n",
    "            sum = sum + 1\n",
    "        if pred[0] == 9:\n",
    "            num_9 += 1\n",
    "        \"\"\"\n",
    "        plt.figure(dpi=50,figsize=(32,32))\n",
    "        for i in range(0, 10):\n",
    "            mask, logit = gradcam(normed_img, class_idx=i)\n",
    "    \n",
    "            # make heatmap from mask and synthesize saliency map using heatmap and img\n",
    "            heatmap, cam_result = visualize_cam(mask, torch_img)\n",
    "        \n",
    "            \n",
    "            # plt.subplot(1,2,1)\n",
    "            \n",
    "            # plt.imshow(transforms.ToPILImage()(heatmap))\n",
    "            plt.subplot(1, 10, i+1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(transforms.ToPILImage()(cam_result))\n",
    "            # plt.title(label_dict[i])\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "    print(f\"预测正确的数量：{sum}\")\n",
    "    print(f\"中毒的数量：{num_9}\")\n",
    "        \n",
    "        \n",
    "# train训练良性，中毒的用poison_test训练，\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('neurotoxin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "378785f2707e7431a0c2e8501b127f30537e5fa363a2986e3a7aec34d42a13b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
